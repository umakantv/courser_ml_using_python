{"cells":[{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"# Neural Network - Backpropagation\n\n## Terminology\n\n$ s_l $ : no of nodes in layer $ l $  \n$ a^{(l)} $ : activation nodes for layer $ l $ , has dimension $ [m \\times (s_{l}+1)] $ including the bias unit  \n$ \\Theta^{(l)} $ : weights for layer $ l $, has dimension $ [ (s_{l}+1) \\times s_{l+1} ] $  \n$ K $ : No of Output Units  \n$ L $ : No of Layers\n\n$ a^{(1)} = X = $ input layer - $ [m \\times (n+1)] $   \n$ \\Theta^{(2)} $ - $ [s_2 \\times (n+1)] $\n\n$ a^{(2)} = g(a^{(1)}. {\\Theta^{(2)}}^T ) $ - $  [m \\times (s_2)] $  ( add ($ a^{(2)}_0 $) )  \n\n\nand so on..."},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"## Cost Function\n$$ J(\\Theta) = - \\frac{1}{m} [ \\sum^{m}_{i=1} \\sum^{K}_{k = 1} y_{i k} log(h_{\\theta} (x_i)_k ) + (1- y_{i k}) log(1- h_{\\theta} (x_i)_k )] + \\frac{\\lambda}{2m} \\sum^{L}_{l=2} \\sum^{s_l}_{i=1} \\sum^{s_{l+1}}_{j=1} (\\Theta^{(l)}_{ij})^2  $$"},{"cell_type":"markdown","execution_count":1,"metadata":{},"outputs":[{"ename":"SyntaxError","evalue":"invalid syntax (<ipython-input-1-3afca619a77b>, line 2)","output_type":"error","traceback":["\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-3afca619a77b>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    $ $\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"]}],"source":"## Gradient Function\nFor $ L = 4$ $, s_1 = 3$, $s_2 = 5$, $s_3 = 5$, $s_4 = K = 4 $  \n\n$ \\delta^{(l)}_{j} :$ \"error\" in the activation of node $ j$ in layer $l$  \n\n$ \\delta^{(4)} = a^{(4)} - y $ - has dimensions $[m \\times s_4]$  \n\n$ \\delta^{(3)} =  \\delta^{(4)} (\\Theta^{(4)})^T .* g'(z^{(4)}) $ - has dimensions $[m \\times s_4]$  \nwhere, $ g'(z^{(4)}) = g(z^{(4)}) .* (1 - g(z^{(4)})) $  \n\nTherefore,  \n$ \\delta^{(4)} =  \\delta^{(4)} (\\Theta^{(4)})^T .* a^{(4)} .* (1 - a^{(4)} )  $  \n\nand so on..."},{"cell_type":"code","execution_count":229,"metadata":{},"outputs":[],"source":"import numpy as np\nimport scipy.optimize as op\nimport scipy.io as sio\nimport matplotlib.pyplot as plt"},{"cell_type":"code","execution_count":230,"metadata":{},"outputs":[],"source":"data = sio.loadmat('Practice\\Machine Learning\\machine-learning-ex3\\ex3\\ex3data1.mat')\nX = data['X']\nX = np.insert(arr=X, obj=0, values=1.0, axis=1)\ny = data['y']\nm, n = X.shape\nK = 10\nY = np.zeros((m, 10))\n# saving no of neurons in s\nS = [400, 25, 10]   # excluding bias\n# for predicting digit = 0, we get h high as index 9 (0 based)\n# therefore we create Y as\n# [1, 0, 0, ... 0] for 1\n# [0, 1, 0, ... 0] for 2\n# [0, 0, 0, ... 1] for 0\nfor i in range(1, K+1):\n    Y[np.where(y == i)[0], i-1] = 1\n"},{"cell_type":"code","execution_count":231,"metadata":{},"outputs":[],"source":"def sigmoid(Z):\n    return 1/(1+ 1/(np.e**Z))"},{"cell_type":"code","execution_count":253,"metadata":{},"outputs":[],"source":"# np.where( H == np.amax(H, axis=1).reshape((m, 1)) )[1]\n# thetas = 3d matrix where thetas[0] = theta matrix for layer 1\n# y = m x 10 shaped matrix\ndef costFunc(thetas, X, Y, lbd, S):\n    m, n = X.shape\n    Y = Y.reshape((m, S[2]))\n    \n    theta1 = thetas[:(S[0]+1)*S[1]]\n    theta2 = thetas[(S[0]+1)*S[1]:]\n    theta1 = theta1.reshape((S[1], S[0]+1))    # 25 x 401\n    theta2 = theta2.reshape((S[2], S[1]+1))    # 10 x 26\n\n    theta1 = theta1.T       # n x 25\n    theta2 = theta2.T       # 26 x 10\n    Z2 = X.dot(theta1)      # M x 25\n    A2 = sigmoid(Z2)        \n    A2 = np.insert(arr=A2, obj=0, values=1.0, axis=1)   # M x 26\n    Z3 = A2.dot(theta2)\n    A3 = sigmoid(Z3)        # M X 10\n\n    cost = -1/m*np.sum(Y*np.log(A3)+(1-Y)*np.log(1-A3))\n    cost += lbd /(2*m) * (np.sum(theta1[1:, :]**2) + np.sum(theta2[1:, :]**2) )\n    return cost"},{"cell_type":"code","execution_count":254,"metadata":{},"outputs":[{"data":{"text/plain":"0.38376985909092365"},"execution_count":254,"metadata":{},"output_type":"execute_result"}],"source":"test_thetas = sio.loadmat('Practice\\Machine Learning\\machine-learning-ex4\\ex4\\ex4weights.mat')\ntest_thetas = np.array(np.append(test_thetas['Theta1'], test_thetas['Theta2']) )\nlbd = 1\ncost = costFunc(test_thetas, X, Y, lbd, S)\ncost"},{"cell_type":"code","execution_count":255,"metadata":{},"outputs":[],"source":"def predict(thetas, X, S):\n    m, n = X.shape\n    \n    theta1 = thetas[:(S[0]+1)*S[1]]\n    theta2 = thetas[(S[0]+1)*S[1]:]\n    theta1 = theta1.reshape((S[1], S[0]+1))    # 25 x 401\n    theta2 = theta2.reshape((S[2], S[1]+1))    # 10 x 26\n\n    theta1 = theta1.T       # n x 25\n    theta2 = theta2.T       # 26 x 10\n    Z2 = X.dot(theta1)      # M x 25\n    A2 = sigmoid(Z2)        \n    A2 = np.insert(arr=A2, obj=0, values=1.0, axis=1)   # M x 26\n    # print(A2.shape)\n    Z3 = A2.dot(theta2)\n    A3 = sigmoid(Z3)        # M X 10\n    # print(A3.shape)\n\n    # choose column wise max index for each example\n    # np.amax(A3, 1) gives each rows max values in an array\n    # np.amax(A3, 1) gives each columns max values in an array\n\n    # np.amax().reshape() make that a column vector\n    # np.where(A3 = ... ) gives two arrays:\n    # 1. Indices of rows for each match\n    # 2. Indices of columns for each match\n    # if an element doesn't match, it is ignored\n    # we only want the indices of columns\n    return np.where(A3 == np.amax(A3, axis=1).reshape((m, 1)) )[1].reshape(m, 1)+1\n"},{"cell_type":"code","execution_count":256,"metadata":{},"outputs":[{"data":{"text/plain":"97.52"},"execution_count":256,"metadata":{},"output_type":"execute_result"}],"source":"test_result = predict(test_thetas, X, S)\ny[test_result==y].size/m*100"},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"## Backpropagation"},{"cell_type":"code","execution_count":257,"metadata":{},"outputs":[],"source":"def sigmoidGrad(Z):\n    p = sigmoid(Z)\n    return p*(1-p)"},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":""},{"cell_type":"code","execution_count":258,"metadata":{},"outputs":[],"source":"def gradFunc(thetas, X, Y, lbd, S):\n    m, n = X.shape\n    Y = Y.reshape((m, S[2]))\n    \n    theta1 = thetas[:(S[0]+1)*S[1]]\n    theta2 = thetas[(S[0]+1)*S[1]:]\n    theta1 = theta1.reshape((S[1], S[0]+1))    # 25 x 401\n    theta2 = theta2.reshape((S[2], S[1]+1))    # 10 x 26\n\n    Z2 = X.dot(theta1.T)      # M x 25\n    A2 = sigmoid(Z2)        \n    A2 = np.insert(arr=A2, obj=0, values=1.0, axis=1)   # M x 26\n    Z3 = A2.dot(theta2.T)\n    A3 = sigmoid(Z3)        # M X 10\n\n    error3 = A3 - Y     # M x 10\n    temp3 = error3 * sigmoidGrad(Z3)    # M x 10\n    grad3 = temp3.T.dot(A2)             # 10 * 26\n    grad3[:, 1:] += (lbd/m)*theta2[:, 1:]\n\n    error2 = temp3.dot(theta2[:, 1:])   # M x 25\n    temp2 = error2 * sigmoidGrad(Z2)\n    grad2 = temp2.T.dot(X)              # 25 x 401\n    grad2[:, 1:] += (lbd/m)*theta1[:, 1:]\n\n    return np.array(np.append(grad2, grad3) ).reshape((grad2.size+grad3.size, 1))"},{"cell_type":"code","execution_count":259,"metadata":{},"outputs":[],"source":"def randInitWeights(S):\n    import numpy.random as random\n    t1 = random.rand(S[1], S[0]+1)\n    t2 = random.rand(S[2], S[1]+1)\n    return np.array(np.append(t1, t2)).reshape((t1.size+t2.size, 1))"},{"cell_type":"code","execution_count":262,"metadata":{},"outputs":[{"data":{"text/plain":"array([[ 1.84729241e+00],\n       [-2.11248326e-12],\n       [ 4.38829369e-13],\n       ...,\n       [-8.86147373e-01],\n       [-1.25990633e+00],\n       [-9.84894986e-02]])"},"execution_count":262,"metadata":{},"output_type":"execute_result"}],"source":"thetas = randInitWeights(S)\ngrad = gradFunc(test_thetas, X, Y, 1, S)\ngrad"},{"cell_type":"code","execution_count":264,"metadata":{},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m<ipython-input-264-c3e0e2341912>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m temp = op.minimize(fun=costFunc, x0=thetas,\n\u001b[0;32m      2\u001b[0m                 \u001b[0mjac\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgradFunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m                 method='TNC')\n\u001b[0m","\u001b[1;32mC:\\Python\\Python37\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    604\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tnc'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n\u001b[1;32m--> 606\u001b[1;33m                              **options)\n\u001b[0m\u001b[0;32m    607\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'cobyla'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_minimize_cobyla\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mC:\\Python\\Python37\\lib\\site-packages\\scipy\\optimize\\tnc.py\u001b[0m in \u001b[0;36m_minimize_tnc\u001b[1;34m(fun, x0, args, jac, bounds, eps, scale, offset, mesg_num, maxCGit, maxiter, eta, stepmx, accuracy, minfev, ftol, xtol, gtol, rescale, disp, callback, **unknown_options)\u001b[0m\n\u001b[0;32m    407\u001b[0m                                         \u001b[0moffset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxCGit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxfun\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m                                         \u001b[0meta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstepmx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mftol\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 409\u001b[1;33m                                         xtol, pgtol, rescale, callback)\n\u001b[0m\u001b[0;32m    410\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m     \u001b[0mfunv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjacv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mC:\\Python\\Python37\\lib\\site-packages\\scipy\\optimize\\tnc.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    370\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 372\u001b[1;33m             \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    373\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m<ipython-input-258-e43605d57a78>\u001b[0m in \u001b[0;36mgradFunc\u001b[1;34m(thetas, X, Y, lbd, S)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0merror2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemp3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# M x 25\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mtemp2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msigmoidGrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mgrad2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemp2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m              \u001b[1;31m# 25 x 401\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mgrad2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlbd\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtheta1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":"temp = op.minimize(fun=costFunc, x0=thetas,\n                jac=gradFunc, args=(X, Y, 1, S), \n                method='TNC')"},{"cell_type":"code","execution_count":252,"metadata":{},"outputs":[{"data":{"text/plain":"     fun: 37.0842319950128\n     jac: array([[-1.11355333e-05],\n       [ 1.16433611e-04],\n       [ 4.25305774e-05],\n       ...,\n       [ 4.44117280e+02],\n       [ 4.44117896e+02],\n       [ 4.44118343e+02]])\n message: 'Converged (|f_n-f_(n-1)| ~= 0)'\n    nfev: 84\n     nit: 4\n  status: 1\n success: True\n       x: array([ 0.15861498,  0.58216806,  0.21265289, ..., -0.19302521,\n       -0.00464629, -0.10443207])"},"execution_count":252,"metadata":{},"output_type":"execute_result"}],"source":"# thetas= temp.jac.reshape((1, test_thetas.size))\ntemp\n# theta1 = thetas[:(S[0]+1)*S[1]]\n# theta2 = thetas[(S[0]+1)*S[1]:]\n# theta1 = theta1.reshape((S[1], S[0]+1))    # 25 x 401\n# theta2 = theta2.reshape((S[2], S[1]+1))    # 10 x 26\n"},{"cell_type":"code","execution_count":249,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"[-2.25623899e-02 -1.05624163e-08  2.19414684e-09 ... -2.47795788e-01\n  1.28009118e+00 -1.32752042e+00]\nC:\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in power\n  \n"},{"data":{"text/plain":"array([[10],\n       [10],\n       [10],\n       ...,\n       [10],\n       [10],\n       [10]], dtype=int32)"},"execution_count":249,"metadata":{},"output_type":"execute_result"}],"source":"print(test_thetas)\npredict(thetas, X, S)"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}