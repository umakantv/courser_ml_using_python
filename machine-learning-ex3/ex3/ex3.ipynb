{"cells":[{"cell_type":"markdown","execution_count":1,"metadata":{},"outputs":[],"source":"# Multi-class Classification\n## One-vs-all Logisitic Regression"},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport scipy.io as sio\nimport scipy.optimize as op\nimport copy"},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":"data = sio.loadmat(\"Practice\\Machine Learning\\machine-learning-ex3\\ex3\\ex3data1.mat\")\ndata['X'] = np.insert(arr=data['X'], obj=0, values=1.0, axis=1)\nX = data['X']\ny = data['y']\nm, n = X.shape"},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":"def sigmoid(Z):\n    return 1/(1+ 1/(np.e**Z))"},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[],"source":"def costFunc(theta, X, y, lbd):\n    m, n = X.shape\n    y = y.reshape((m, 1))\n    theta = theta.reshape((n, 1))\n    Z = X.dot(theta) # M x 1\n    H = sigmoid(Z)\n    cost = 1/m*(-1 * y.T.dot(np.log(H)) - (1-y).T.dot(np.log(1-H)) )\n    cost = cost + lbd/(2*m)*( np.sum(theta*theta)-theta[0]**2 )\n    return cost"},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":"def gradFunc(theta, X, y, lbd):\n    m, n = X.shape\n    y = y.reshape((m, 1))\n    theta = theta.reshape((n, 1))\n    Z = X.dot(theta)\n    H = sigmoid(Z) # M x 1\n    grad = 1/m *( X.T.dot(H-y) + lbd*theta )\n    grad[0] = grad[0] - lbd/m * theta[0]\n    return grad"},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[],"source":"def oneVsAll(X, y, k, lmbda):\n    # k classes\n    m, n = X.shape\n    theta = []\n    for i in range(k):\n            # iterate for i: [0:9]\n            # mapping 1 -> theta[:, 0]\n            # mapping 2 -> theta[:, 1]\n            # ...\n            # mapping 9 -> theta[:, 8]\n            # mapping 0 -> theta[:, 9]\n            yf = copy.deepcopy(y)\n            yf[y!=i+1] = 0\n            yf[y==i+1] = 1\n            temp = op.minimize(\n                fun=costFunc, x0=np.zeros((n, 1)),\n                jac=gradFunc, args=(X, yf, lmbda), \n                method='TNC')\n            theta.append(temp['x'])\n    return np.array(theta).T"},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[],"source":"k = 10\ntheta = oneVsAll(X, y, 10, 1)"},{"cell_type":"code","execution_count":75,"metadata":{},"outputs":[],"source":"# predict\nprint(theta[0:5, 0:5])\nZ = X.dot(theta)\nH = sigmoid(Z)\np = np.where( H == np.amax(H, axis=1).reshape((m, 1)) )[1]\np = p+1\np = p.reshape((m, 1))\n"},{"cell_type":"code","execution_count":80,"metadata":{},"outputs":[],"source":"# Accuracy\nacc= p[p == y].size/m*100\nprint(acc)"}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}